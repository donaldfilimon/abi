
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Modern Zig framework for modular AI services, vector search, and systems tooling.">
      
      
      
      
      
      
        
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>2026-01-17-cuda-vtable-wrapper - ABI Framework</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.484c7ddc.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#cuda-vtable-wrapper-implementation-plan" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="ABI Framework" class="md-header__button md-logo" aria-label="ABI Framework" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            ABI Framework
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              2026-01-17-cuda-vtable-wrapper
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/donaldfilimon/abi" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../docs/intro.md" class="md-tabs__link">
        
  
  
    
  
  Introduction

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../docs/framework.md" class="md-tabs__link">
        
  
  
    
  
  Framework

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../docs/compute.md" class="md-tabs__link">
        
  
  
    
  
  Compute

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../docs/gpu.md" class="md-tabs__link">
        
  
  
    
  
  GPU

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../docs/database.md" class="md-tabs__link">
        
  
  
    
  
  Database

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../docs/network.md" class="md-tabs__link">
        
  
  
    
  
  Network

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../docs/monitoring.md" class="md-tabs__link">
        
  
  
    
  
  Monitoring

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../docs/ai.md" class="md-tabs__link">
        
  
  
    
  
  AI

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../docs/migration/zig-0.16-migration.md" class="md-tabs__link">
          
  
  
  Migration

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="ABI Framework" class="md-nav__button md-logo" aria-label="ABI Framework" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    ABI Framework
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/donaldfilimon/abi" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../docs/intro.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Introduction
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../docs/framework.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Framework
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../docs/compute.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Compute
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../docs/gpu.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    GPU
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../docs/database.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Database
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../docs/network.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Network
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../docs/monitoring.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Monitoring
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../docs/ai.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    AI
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9" >
        
          
          <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Migration
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            
  
    Migration
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../docs/migration/zig-0.16-migration.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Zig 0.16 Migration
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#task-1-create-cudabackend-struct" class="md-nav__link">
    <span class="md-ellipsis">
      
        Task 1: Create CudaBackend Struct
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#task-2-implement-device-info-methods" class="md-nav__link">
    <span class="md-ellipsis">
      
        Task 2: Implement Device Info Methods
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#task-3-implement-memory-operations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Task 3: Implement Memory Operations
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#task-4-implement-kernel-compilation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Task 4: Implement Kernel Compilation
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#task-5-implement-kernel-launch-and-synchronization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Task 5: Implement Kernel Launch and Synchronization
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#task-6-create-vtable-wrapper-function" class="md-nav__link">
    <span class="md-ellipsis">
      
        Task 6: Create VTable Wrapper Function
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#task-7-export-from-cuda-module" class="md-nav__link">
    <span class="md-ellipsis">
      
        Task 7: Export from CUDA Module
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#task-8-integrate-with-backend-factory" class="md-nav__link">
    <span class="md-ellipsis">
      
        Task 8: Integrate with Backend Factory
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#task-9-add-integration-test" class="md-nav__link">
    <span class="md-ellipsis">
      
        Task 9: Add Integration Test
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#task-10-update-documentation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Task 10: Update Documentation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Task 10: Update Documentation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#fallback-behavior" class="md-nav__link">
    <span class="md-ellipsis">
      
        Fallback Behavior
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      
        Summary
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="cuda-vtable-wrapper-implementation-plan">CUDA VTable Wrapper Implementation Plan</h1>
<blockquote>
<p><strong>Codebase Status:</strong> Synced with repository as of 2026-01-18.</p>
<p><strong>For Claude:</strong> REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.
<strong>Status:</strong> Implemented âœ… (January 17, 2026)</p>
</blockquote>
<p><strong>Goal:</strong> Create a complete CUDA backend implementation that fully implements the VTable interface, enabling real GPU kernel execution instead of the current simulated fallback.</p>
<p><strong>Architecture:</strong> The CUDA VTable wrapper (<code>CudaBackend</code>) will implement all 12 VTable methods by delegating to the existing CUDA loader and native modules. It wraps the dynamic CUDA driver API calls (cuInit, cuMemAlloc, cuLaunchKernel, etc.) behind the polymorphic VTable interface, enabling the dispatcher to execute kernels on actual NVIDIA GPUs.</p>
<p><strong>Tech Stack:</strong> Zig 0.16, CUDA Driver API (nvcuda.dll/libcuda.so), NVRTC for runtime compilation</p>
<hr />
<h2 id="task-1-create-cudabackend-struct">Task 1: Create CudaBackend Struct</h2>
<p><strong>Files:</strong>
- Create: <code>src/compute/gpu/backends/cuda/vtable.zig</code>
- Modify: <code>src/compute/gpu/backends/cuda/mod.zig</code> (add export)</p>
<p><strong>Step 1: Write the failing test</strong></p>
<pre><code class="language-zig">// In src/compute/gpu/backends/cuda/vtable.zig
test &quot;CudaBackend initialization&quot; {
    const allocator = std.testing.allocator;

    // Should create backend or return NotAvailable if no CUDA
    const result = CudaBackend.init(allocator, 0);
    if (result) |backend| {
        defer backend.deinit();
        try std.testing.expect(backend.device_id == 0);
    } else |err| {
        // Expected on systems without CUDA
        try std.testing.expect(err == error.BackendNotAvailable or err == error.InitFailed);
    }
}
</code></pre>
<p><strong>Step 2: Run test to verify it fails</strong></p>
<p>Run: <code>zig test src/compute/gpu/backends/cuda/vtable.zig --test-filter "CudaBackend initialization"</code>
Expected: FAIL with "CudaBackend not defined"</p>
<p><strong>Step 3: Write minimal implementation</strong></p>
<pre><code class="language-zig">//! CUDA VTable Backend Implementation
//!
//! Provides a complete VTable implementation for CUDA, enabling real GPU
//! kernel execution through the polymorphic backend interface.

const std = @import(&quot;std&quot;);
const builtin = @import(&quot;builtin&quot;);
const build_options = @import(&quot;build_options&quot;);
const interface = @import(&quot;../../interface.zig&quot;);
const loader = @import(&quot;loader.zig&quot;);

pub const CudaBackend = struct {
    allocator: std.mem.Allocator,
    device_id: i32,
    context: ?*anyopaque,
    functions: ?loader.CudaFunctions,

    // Track allocations for cleanup
    allocations: std.ArrayListUnmanaged(Allocation),
    kernels: std.ArrayListUnmanaged(CompiledKernel),

    const Allocation = struct {
        ptr: *anyopaque,
        size: usize,
        is_host_pinned: bool,
    };

    const CompiledKernel = struct {
        module: *anyopaque,
        function: *anyopaque,
        name: []const u8,
    };

    const Self = @This();

    pub fn init(allocator: std.mem.Allocator, device_id: i32) interface.BackendError!*Self {
        // Check if CUDA is enabled at compile time
        if (comptime !build_options.gpu_cuda) {
            return interface.BackendError.NotAvailable;
        }

        // Try to load CUDA driver
        const functions = loader.loadCudaFunctions() catch {
            return interface.BackendError.NotAvailable;
        };

        // Initialize CUDA
        const init_result = functions.core.cuInit(0);
        if (init_result != 0) {
            return interface.BackendError.InitFailed;
        }

        // Check device count
        var device_count: c_int = 0;
        const count_result = functions.device.cuDeviceGetCount(&amp;device_count);
        if (count_result != 0 or device_count == 0) {
            return interface.BackendError.DeviceNotFound;
        }

        if (device_id &gt;= device_count) {
            return interface.BackendError.DeviceNotFound;
        }

        // Get device handle
        var device: c_int = undefined;
        const device_result = functions.core.cuDeviceGet(&amp;device, device_id);
        if (device_result != 0) {
            return interface.BackendError.DeviceNotFound;
        }

        // Create context
        var context: ?*anyopaque = null;
        const ctx_result = functions.core.cuCtxCreate(&amp;context, 0, device);
        if (ctx_result != 0) {
            return interface.BackendError.InitFailed;
        }

        const self = allocator.create(Self) catch {
            // Destroy context on allocation failure
            if (context) |ctx| {
                _ = functions.core.cuCtxDestroy(ctx);
            }
            return interface.BackendError.OutOfMemory;
        };

        self.* = .{
            .allocator = allocator,
            .device_id = device_id,
            .context = context,
            .functions = functions,
            .allocations = .empty,
            .kernels = .empty,
        };

        return self;
    }

    pub fn deinit(self: *Self) void {
        // Free all allocations
        if (self.functions) |funcs| {
            for (self.allocations.items) |alloc| {
                if (alloc.is_host_pinned) {
                    _ = funcs.memory.cuMemFreeHost(alloc.ptr);
                } else {
                    _ = funcs.memory.cuMemFree(@intFromPtr(alloc.ptr));
                }
            }

            // Destroy all kernels
            for (self.kernels.items) |kernel| {
                _ = funcs.kernel.cuModuleUnload(kernel.module);
            }

            // Destroy context
            if (self.context) |ctx| {
                _ = funcs.core.cuCtxDestroy(ctx);
            }
        }

        self.allocations.deinit(self.allocator);
        self.kernels.deinit(self.allocator);
        self.allocator.destroy(self);
    }
};
</code></pre>
<p><strong>Step 4: Run test to verify it passes</strong></p>
<p>Run: <code>zig test src/compute/gpu/backends/cuda/vtable.zig --test-filter "CudaBackend initialization"</code>
Expected: PASS (or skip on non-CUDA systems)</p>
<p><strong>Step 5: Commit</strong></p>
<pre><code class="language-bash">git add src/compute/gpu/backends/cuda/vtable.zig
git commit -m &quot;feat(gpu): add CudaBackend struct with init/deinit&quot;
</code></pre>
<hr />
<h2 id="task-2-implement-device-info-methods">Task 2: Implement Device Info Methods</h2>
<p><strong>Files:</strong>
- Modify: <code>src/compute/gpu/backends/cuda/vtable.zig</code></p>
<p><strong>Step 1: Write the failing test</strong></p>
<pre><code class="language-zig">test &quot;CudaBackend device info&quot; {
    const allocator = std.testing.allocator;

    const backend = CudaBackend.init(allocator, 0) catch |err| {
        if (err == error.BackendNotAvailable or err == error.DeviceNotFound) {
            return error.SkipZigTest;
        }
        return err;
    };
    defer backend.deinit();

    // Test getDeviceCount
    const count = backend.getDeviceCount();
    try std.testing.expect(count &gt; 0);

    // Test getDeviceCaps
    const caps = try backend.getDeviceCaps(0);
    try std.testing.expect(caps.total_memory &gt; 0);
    try std.testing.expect(caps.compute_capability[0] &gt; 0);
}
</code></pre>
<p><strong>Step 2: Run test to verify it fails</strong></p>
<p>Run: <code>zig test src/compute/gpu/backends/cuda/vtable.zig --test-filter "device info"</code>
Expected: FAIL with "no member named 'getDeviceCount'"</p>
<p><strong>Step 3: Write minimal implementation</strong></p>
<pre><code class="language-zig">    // Add these methods to CudaBackend struct:

    pub fn getDeviceCount(self: *Self) u32 {
        const funcs = self.functions orelse return 0;
        var count: c_int = 0;
        const result = funcs.device.cuDeviceGetCount(&amp;count);
        if (result != 0) return 0;
        return @intCast(@max(0, count));
    }

    pub fn getDeviceCaps(self: *Self, device_id: u32) interface.BackendError!interface.DeviceCaps {
        const funcs = self.functions orelse return interface.BackendError.NotAvailable;

        var device: c_int = undefined;
        if (funcs.core.cuDeviceGet(&amp;device, @intCast(device_id)) != 0) {
            return interface.BackendError.DeviceNotFound;
        }

        var caps = interface.DeviceCaps{
            .name = undefined,
            .name_len = 0,
            .total_memory = 0,
            .shared_memory_per_block = 0,
            .max_threads_per_block = 0,
            .max_block_dims = .{ 0, 0, 0 },
            .max_grid_dims = .{ 0, 0, 0 },
            .warp_size = 32,
            .compute_capability = .{ 0, 0 },
            .supports_f16 = false,
            .supports_f64 = true,
            .supports_atomics = true,
            .supports_dynamic_parallelism = false,
        };

        // Get device name
        var name_buf: [256]u8 = undefined;
        if (funcs.device.cuDeviceGetName(&amp;name_buf, 256, device) == 0) {
            const len = std.mem.indexOfScalar(u8, &amp;name_buf, 0) orelse 256;
            @memcpy(caps.name[0..len], name_buf[0..len]);
            caps.name_len = len;
        }

        // Get total memory
        var total_mem: usize = 0;
        if (funcs.device.cuDeviceTotalMem(&amp;total_mem, device) == 0) {
            caps.total_memory = total_mem;
        }

        // Get compute capability
        var major: c_int = 0;
        var minor: c_int = 0;
        _ = funcs.device.cuDeviceGetAttribute(&amp;major, 75, device); // CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MAJOR
        _ = funcs.device.cuDeviceGetAttribute(&amp;minor, 76, device); // CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MINOR
        caps.compute_capability = .{ @intCast(@max(0, major)), @intCast(@max(0, minor)) };

        // Get other attributes
        var val: c_int = 0;
        if (funcs.device.cuDeviceGetAttribute(&amp;val, 1, device) == 0) { // MAX_THREADS_PER_BLOCK
            caps.max_threads_per_block = @intCast(@max(0, val));
        }
        if (funcs.device.cuDeviceGetAttribute(&amp;val, 8, device) == 0) { // MAX_SHARED_MEMORY_PER_BLOCK
            caps.shared_memory_per_block = @intCast(@max(0, val));
        }
        if (funcs.device.cuDeviceGetAttribute(&amp;val, 2, device) == 0) caps.max_block_dims[0] = @intCast(@max(0, val));
        if (funcs.device.cuDeviceGetAttribute(&amp;val, 3, device) == 0) caps.max_block_dims[1] = @intCast(@max(0, val));
        if (funcs.device.cuDeviceGetAttribute(&amp;val, 4, device) == 0) caps.max_block_dims[2] = @intCast(@max(0, val));
        if (funcs.device.cuDeviceGetAttribute(&amp;val, 5, device) == 0) caps.max_grid_dims[0] = @intCast(@max(0, val));
        if (funcs.device.cuDeviceGetAttribute(&amp;val, 6, device) == 0) caps.max_grid_dims[1] = @intCast(@max(0, val));
        if (funcs.device.cuDeviceGetAttribute(&amp;val, 7, device) == 0) caps.max_grid_dims[2] = @intCast(@max(0, val));
        if (funcs.device.cuDeviceGetAttribute(&amp;val, 10, device) == 0) caps.warp_size = @intCast(@max(1, val));

        // FP16 support (compute &gt;= 5.3)
        caps.supports_f16 = caps.compute_capability[0] &gt; 5 or
            (caps.compute_capability[0] == 5 and caps.compute_capability[1] &gt;= 3);

        // Dynamic parallelism (compute &gt;= 3.5)
        caps.supports_dynamic_parallelism = caps.compute_capability[0] &gt; 3 or
            (caps.compute_capability[0] == 3 and caps.compute_capability[1] &gt;= 5);

        return caps;
    }
</code></pre>
<p><strong>Step 4: Run test to verify it passes</strong></p>
<p>Run: <code>zig test src/compute/gpu/backends/cuda/vtable.zig --test-filter "device info"</code>
Expected: PASS (or SkipZigTest on non-CUDA)</p>
<p><strong>Step 5: Commit</strong></p>
<pre><code class="language-bash">git add src/compute/gpu/backends/cuda/vtable.zig
git commit -m &quot;feat(gpu): add CudaBackend device info methods&quot;
</code></pre>
<hr />
<h2 id="task-3-implement-memory-operations">Task 3: Implement Memory Operations</h2>
<p><strong>Files:</strong>
- Modify: <code>src/compute/gpu/backends/cuda/vtable.zig</code></p>
<p><strong>Step 1: Write the failing test</strong></p>
<pre><code class="language-zig">test &quot;CudaBackend memory operations&quot; {
    const allocator = std.testing.allocator;

    const backend = CudaBackend.init(allocator, 0) catch |err| {
        if (err == error.BackendNotAvailable or err == error.DeviceNotFound) {
            return error.SkipZigTest;
        }
        return err;
    };
    defer backend.deinit();

    // Allocate device memory
    const size: usize = 1024;
    const ptr = try backend.allocate(size, .{});
    defer backend.free(ptr);

    // Test copy to device
    var host_data: [256]f32 = undefined;
    for (&amp;host_data, 0..) |*v, i| v.* = @floatFromInt(i);
    try backend.copyToDevice(ptr, std.mem.sliceAsBytes(&amp;host_data));

    // Test copy from device
    var result: [256]f32 = undefined;
    try backend.copyFromDevice(std.mem.sliceAsBytes(&amp;result), ptr);

    try std.testing.expectApproxEqAbs(host_data[0], result[0], 0.001);
    try std.testing.expectApproxEqAbs(host_data[255], result[255], 0.001);
}
</code></pre>
<p><strong>Step 2: Run test to verify it fails</strong></p>
<p>Run: <code>zig test src/compute/gpu/backends/cuda/vtable.zig --test-filter "memory operations"</code>
Expected: FAIL with "no member named 'allocate'"</p>
<p><strong>Step 3: Write minimal implementation</strong></p>
<pre><code class="language-zig">    // Add these methods to CudaBackend struct:

    pub fn allocate(self: *Self, size: usize, flags: interface.MemoryFlags) interface.MemoryError!*anyopaque {
        const funcs = self.functions orelse return interface.MemoryError.OutOfMemory;

        var ptr: usize = 0;
        const result = if (flags.host_visible)
            funcs.memory.cuMemAllocHost(@ptrCast(&amp;ptr), size)
        else
            funcs.memory.cuMemAlloc(&amp;ptr, size);

        if (result != 0) {
            return interface.MemoryError.OutOfMemory;
        }

        const alloc_ptr: *anyopaque = @ptrFromInt(ptr);

        // Track allocation
        self.allocations.append(self.allocator, .{
            .ptr = alloc_ptr,
            .size = size,
            .is_host_pinned = flags.host_visible,
        }) catch {
            // Free on tracking failure
            if (flags.host_visible) {
                _ = funcs.memory.cuMemFreeHost(alloc_ptr);
            } else {
                _ = funcs.memory.cuMemFree(ptr);
            }
            return interface.MemoryError.OutOfMemory;
        };

        return alloc_ptr;
    }

    pub fn free(self: *Self, ptr: *anyopaque) void {
        const funcs = self.functions orelse return;

        // Find and remove from tracking
        for (self.allocations.items, 0..) |alloc, i| {
            if (alloc.ptr == ptr) {
                if (alloc.is_host_pinned) {
                    _ = funcs.memory.cuMemFreeHost(ptr);
                } else {
                    _ = funcs.memory.cuMemFree(@intFromPtr(ptr));
                }
                _ = self.allocations.swapRemove(i);
                return;
            }
        }
    }

    pub fn copyToDevice(self: *Self, dst: *anyopaque, src: []const u8) interface.MemoryError!void {
        const funcs = self.functions orelse return interface.MemoryError.TransferFailed;

        const result = funcs.memory.cuMemcpyHtoD(@intFromPtr(dst), src.ptr, src.len);
        if (result != 0) {
            return interface.MemoryError.TransferFailed;
        }
    }

    pub fn copyFromDevice(self: *Self, dst: []u8, src: *anyopaque) interface.MemoryError!void {
        const funcs = self.functions orelse return interface.MemoryError.TransferFailed;

        const result = funcs.memory.cuMemcpyDtoH(dst.ptr, @intFromPtr(src), dst.len);
        if (result != 0) {
            return interface.MemoryError.TransferFailed;
        }
    }
</code></pre>
<p><strong>Step 4: Run test to verify it passes</strong></p>
<p>Run: <code>zig test src/compute/gpu/backends/cuda/vtable.zig --test-filter "memory operations"</code>
Expected: PASS (or SkipZigTest)</p>
<p><strong>Step 5: Commit</strong></p>
<pre><code class="language-bash">git add src/compute/gpu/backends/cuda/vtable.zig
git commit -m &quot;feat(gpu): add CudaBackend memory operations&quot;
</code></pre>
<hr />
<h2 id="task-4-implement-kernel-compilation">Task 4: Implement Kernel Compilation</h2>
<p><strong>Files:</strong>
- Modify: <code>src/compute/gpu/backends/cuda/vtable.zig</code></p>
<p><strong>Step 1: Write the failing test</strong></p>
<pre><code class="language-zig">test &quot;CudaBackend kernel compilation&quot; {
    const allocator = std.testing.allocator;

    const backend = CudaBackend.init(allocator, 0) catch |err| {
        if (err == error.BackendNotAvailable or err == error.DeviceNotFound) {
            return error.SkipZigTest;
        }
        return err;
    };
    defer backend.deinit();

    // Simple CUDA kernel
    const kernel_source =
        \\extern &quot;C&quot; __global__ void vector_add(float* a, float* b, float* c, int n) {
        \\    int i = blockIdx.x * blockDim.x + threadIdx.x;
        \\    if (i &lt; n) c[i] = a[i] + b[i];
        \\}
    ;

    const kernel = backend.compileKernel(allocator, kernel_source, &quot;vector_add&quot;) catch |err| {
        // NVRTC might not be available
        if (err == error.CompileFailed) return error.SkipZigTest;
        return err;
    };
    defer backend.destroyKernel(kernel);

    try std.testing.expect(kernel != null);
}
</code></pre>
<p><strong>Step 2: Run test to verify it fails</strong></p>
<p>Run: <code>zig test src/compute/gpu/backends/cuda/vtable.zig --test-filter "kernel compilation"</code>
Expected: FAIL with "no member named 'compileKernel'"</p>
<p><strong>Step 3: Write minimal implementation</strong></p>
<pre><code class="language-zig">    // Add these methods to CudaBackend struct:

    pub fn compileKernel(
        self: *Self,
        alloc: std.mem.Allocator,
        source: []const u8,
        entry_point: []const u8,
    ) interface.KernelError!*anyopaque {
        const funcs = self.functions orelse return interface.KernelError.CompileFailed;

        // Use NVRTC to compile
        const nvrtc = @import(&quot;nvrtc.zig&quot;);

        // Compile to PTX
        const ptx = nvrtc.compileSourceToPtx(alloc, source, &amp;.{}) catch {
            return interface.KernelError.CompileFailed;
        };
        defer alloc.free(ptx);

        // Load module from PTX
        var module: ?*anyopaque = null;
        const load_result = funcs.kernel.cuModuleLoadData(&amp;module, ptx.ptr);
        if (load_result != 0 or module == null) {
            return interface.KernelError.CompileFailed;
        }
        errdefer _ = funcs.kernel.cuModuleUnload(module.?);

        // Get function from module
        var function: ?*anyopaque = null;
        const entry_z = alloc.dupeZ(u8, entry_point) catch {
            _ = funcs.kernel.cuModuleUnload(module.?);
            return interface.KernelError.CompileFailed;
        };
        defer alloc.free(entry_z);

        const func_result = funcs.kernel.cuModuleGetFunction(&amp;function, module.?, entry_z.ptr);
        if (func_result != 0 or function == null) {
            _ = funcs.kernel.cuModuleUnload(module.?);
            return interface.KernelError.CompileFailed;
        }

        // Track kernel
        const name_copy = alloc.dupe(u8, entry_point) catch {
            _ = funcs.kernel.cuModuleUnload(module.?);
            return interface.KernelError.CompileFailed;
        };

        self.kernels.append(self.allocator, .{
            .module = module.?,
            .function = function.?,
            .name = name_copy,
        }) catch {
            alloc.free(name_copy);
            _ = funcs.kernel.cuModuleUnload(module.?);
            return interface.KernelError.CompileFailed;
        };

        return function.?;
    }

    pub fn destroyKernel(self: *Self, kernel: *anyopaque) void {
        const funcs = self.functions orelse return;

        for (self.kernels.items, 0..) |k, i| {
            if (k.function == kernel) {
                _ = funcs.kernel.cuModuleUnload(k.module);
                self.allocator.free(k.name);
                _ = self.kernels.swapRemove(i);
                return;
            }
        }
    }
</code></pre>
<p><strong>Step 4: Run test to verify it passes</strong></p>
<p>Run: <code>zig test src/compute/gpu/backends/cuda/vtable.zig --test-filter "kernel compilation"</code>
Expected: PASS (or SkipZigTest)</p>
<p><strong>Step 5: Commit</strong></p>
<pre><code class="language-bash">git add src/compute/gpu/backends/cuda/vtable.zig
git commit -m &quot;feat(gpu): add CudaBackend kernel compilation&quot;
</code></pre>
<hr />
<h2 id="task-5-implement-kernel-launch-and-synchronization">Task 5: Implement Kernel Launch and Synchronization</h2>
<p><strong>Files:</strong>
- Modify: <code>src/compute/gpu/backends/cuda/vtable.zig</code></p>
<p><strong>Step 1: Write the failing test</strong></p>
<pre><code class="language-zig">test &quot;CudaBackend kernel launch&quot; {
    const allocator = std.testing.allocator;

    const backend = CudaBackend.init(allocator, 0) catch |err| {
        if (err == error.BackendNotAvailable or err == error.DeviceNotFound) {
            return error.SkipZigTest;
        }
        return err;
    };
    defer backend.deinit();

    // Compile kernel
    const kernel_source =
        \\extern &quot;C&quot; __global__ void fill(float* out, float val, int n) {
        \\    int i = blockIdx.x * blockDim.x + threadIdx.x;
        \\    if (i &lt; n) out[i] = val;
        \\}
    ;

    const kernel = backend.compileKernel(allocator, kernel_source, &quot;fill&quot;) catch {
        return error.SkipZigTest;
    };
    defer backend.destroyKernel(kernel);

    // Allocate memory
    const n: usize = 256;
    const out_ptr = try backend.allocate(n * @sizeOf(f32), .{});
    defer backend.free(out_ptr);

    // Launch config
    const config = interface.LaunchConfig{
        .grid_dim = .{ 1, 1, 1 },
        .block_dim = .{ 256, 1, 1 },
        .shared_mem = 0,
        .stream = null,
    };

    // Prepare args
    const val: f32 = 42.0;
    const n_val: i32 = @intCast(n);
    var args: [3]*anyopaque = .{
        @ptrCast(&amp;out_ptr),
        @ptrCast(@constCast(&amp;val)),
        @ptrCast(@constCast(&amp;n_val)),
    };

    try backend.launchKernel(kernel, config, &amp;args);
    try backend.synchronize();

    // Verify results
    var result: [256]f32 = undefined;
    try backend.copyFromDevice(std.mem.sliceAsBytes(&amp;result), out_ptr);

    try std.testing.expectApproxEqAbs(@as(f32, 42.0), result[0], 0.001);
    try std.testing.expectApproxEqAbs(@as(f32, 42.0), result[255], 0.001);
}
</code></pre>
<p><strong>Step 2: Run test to verify it fails</strong></p>
<p>Run: <code>zig test src/compute/gpu/backends/cuda/vtable.zig --test-filter "kernel launch"</code>
Expected: FAIL with "no member named 'launchKernel'"</p>
<p><strong>Step 3: Write minimal implementation</strong></p>
<pre><code class="language-zig">    // Add these methods to CudaBackend struct:

    pub fn launchKernel(
        self: *Self,
        kernel: *anyopaque,
        config: interface.LaunchConfig,
        args: []const *anyopaque,
    ) interface.KernelError!void {
        const funcs = self.functions orelse return interface.KernelError.LaunchFailed;

        // Validate config
        if (config.block_dim[0] == 0 or config.block_dim[1] == 0 or config.block_dim[2] == 0) {
            return interface.KernelError.InvalidConfig;
        }
        if (config.grid_dim[0] == 0 or config.grid_dim[1] == 0 or config.grid_dim[2] == 0) {
            return interface.KernelError.InvalidConfig;
        }

        // Build args array for CUDA
        var cuda_args: [32]*anyopaque = undefined;
        const arg_count = @min(args.len, 32);
        for (args[0..arg_count], 0..) |arg, i| {
            cuda_args[i] = @constCast(arg);
        }

        const result = funcs.kernel.cuLaunchKernel(
            kernel,
            config.grid_dim[0],
            config.grid_dim[1],
            config.grid_dim[2],
            config.block_dim[0],
            config.block_dim[1],
            config.block_dim[2],
            config.shared_mem,
            config.stream,
            &amp;cuda_args,
            null, // extra
        );

        if (result != 0) {
            return interface.KernelError.LaunchFailed;
        }
    }

    pub fn synchronize(self: *Self) interface.BackendError!void {
        const funcs = self.functions orelse return interface.BackendError.NotAvailable;

        const result = funcs.core.cuCtxSynchronize();
        if (result != 0) {
            return interface.BackendError.InvalidOperation;
        }
    }
</code></pre>
<p><strong>Step 4: Run test to verify it passes</strong></p>
<p>Run: <code>zig test src/compute/gpu/backends/cuda/vtable.zig --test-filter "kernel launch"</code>
Expected: PASS (or SkipZigTest)</p>
<p><strong>Step 5: Commit</strong></p>
<pre><code class="language-bash">git add src/compute/gpu/backends/cuda/vtable.zig
git commit -m &quot;feat(gpu): add CudaBackend kernel launch and sync&quot;
</code></pre>
<hr />
<h2 id="task-6-create-vtable-wrapper-function">Task 6: Create VTable Wrapper Function</h2>
<p><strong>Files:</strong>
- Modify: <code>src/compute/gpu/backends/cuda/vtable.zig</code></p>
<p><strong>Step 1: Write the failing test</strong></p>
<pre><code class="language-zig">test &quot;CudaBackend as VTable interface&quot; {
    const allocator = std.testing.allocator;

    const backend = createCudaVTable(allocator) catch |err| {
        if (err == error.BackendNotAvailable or err == error.DeviceNotFound) {
            return error.SkipZigTest;
        }
        return err;
    };
    defer backend.deinit();

    // Should work through VTable interface
    const count = backend.getDeviceCount();
    try std.testing.expect(count &gt; 0 or count == 0); // 0 is valid if simulated
}
</code></pre>
<p><strong>Step 2: Run test to verify it fails</strong></p>
<p>Run: <code>zig test src/compute/gpu/backends/cuda/vtable.zig --test-filter "VTable interface"</code>
Expected: FAIL with "createCudaVTable not defined"</p>
<p><strong>Step 3: Write minimal implementation</strong></p>
<pre><code class="language-zig">/// Create a VTable-wrapped CUDA backend.
pub fn createCudaVTable(allocator: std.mem.Allocator) interface.BackendError!interface.Backend {
    const impl = try CudaBackend.init(allocator, 0);
    return interface.createBackend(CudaBackend, impl);
}
</code></pre>
<p><strong>Step 4: Run test to verify it passes</strong></p>
<p>Run: <code>zig test src/compute/gpu/backends/cuda/vtable.zig --test-filter "VTable interface"</code>
Expected: PASS (or SkipZigTest)</p>
<p><strong>Step 5: Commit</strong></p>
<pre><code class="language-bash">git add src/compute/gpu/backends/cuda/vtable.zig
git commit -m &quot;feat(gpu): add createCudaVTable wrapper function&quot;
</code></pre>
<hr />
<h2 id="task-7-export-from-cuda-module">Task 7: Export from CUDA Module</h2>
<p><strong>Files:</strong>
- Modify: <code>src/compute/gpu/backends/cuda/mod.zig</code></p>
<p><strong>Step 1: Read current exports</strong></p>
<p>Read <code>src/compute/gpu/backends/cuda/mod.zig</code> to understand current structure.</p>
<p><strong>Step 2: Add vtable export</strong></p>
<p>Add to mod.zig:</p>
<pre><code class="language-zig">pub const vtable = @import(&quot;vtable.zig&quot;);
pub const CudaBackend = vtable.CudaBackend;
pub const createCudaVTable = vtable.createCudaVTable;
</code></pre>
<p><strong>Step 3: Run build to verify</strong></p>
<p>Run: <code>zig build</code>
Expected: SUCCESS</p>
<p><strong>Step 4: Commit</strong></p>
<pre><code class="language-bash">git add src/compute/gpu/backends/cuda/mod.zig
git commit -m &quot;feat(gpu): export CudaBackend from cuda module&quot;
</code></pre>
<hr />
<h2 id="task-8-integrate-with-backend-factory">Task 8: Integrate with Backend Factory</h2>
<p><strong>Files:</strong>
- Modify: <code>src/compute/gpu/backend_factory.zig</code></p>
<p><strong>Step 1: Read current createCudaVTableBackend</strong></p>
<p>Current implementation now returns the real CUDA backend (legacy TODO resolved).</p>
<p><strong>Step 2: Update to use real CUDA backend</strong></p>
<pre><code class="language-zig">fn createCudaVTableBackend(allocator: std.mem.Allocator) FactoryError!interface.Backend {
    if (comptime !build_options.gpu_cuda) {
        return FactoryError.BackendNotAvailable;
    }

    const cuda = @import(&quot;backends/cuda/mod.zig&quot;);
    return cuda.createCudaVTable(allocator) catch |err| switch (err) {
        error.NotAvailable =&gt; return FactoryError.BackendNotAvailable,
        error.DeviceNotFound =&gt; return FactoryError.BackendNotAvailable,
        error.InitFailed =&gt; return FactoryError.InitFailed,
        error.OutOfMemory =&gt; return FactoryError.OutOfMemory,
        else =&gt; return FactoryError.InitFailed,
    };
}
</code></pre>
<p><strong>Step 3: Run tests</strong></p>
<p>Run: <code>zig build test --summary all</code>
Expected: All tests pass</p>
<p><strong>Step 4: Commit</strong></p>
<pre><code class="language-bash">git add src/compute/gpu/backend_factory.zig
git commit -m &quot;feat(gpu): integrate CudaBackend with backend factory&quot;
</code></pre>
<hr />
<h2 id="task-9-add-integration-test">Task 9: Add Integration Test</h2>
<p><strong>Files:</strong>
- Create: <code>src/compute/gpu/backends/cuda/vtable_test.zig</code></p>
<p><strong>Step 1: Write comprehensive integration test</strong></p>
<pre><code class="language-zig">//! CUDA VTable Integration Tests
//!
//! Tests the complete CUDA backend through the VTable interface.

const std = @import(&quot;std&quot;);
const interface = @import(&quot;../../interface.zig&quot;);
const backend_factory = @import(&quot;../../backend_factory.zig&quot;);

test &quot;CUDA VTable integration - full workflow&quot; {
    const allocator = std.testing.allocator;

    // Create backend via factory
    const backend = backend_factory.createVTableBackend(allocator, .cuda) catch |err| {
        if (err == backend_factory.FactoryError.BackendNotAvailable) {
            return error.SkipZigTest;
        }
        return err;
    };
    defer backend.deinit();

    // 1. Query device info
    const count = backend.getDeviceCount();
    if (count == 0) return error.SkipZigTest;

    const caps = try backend.getDeviceCaps(0);
    std.debug.print(&quot;\nCUDA Device: {s}\n&quot;, .{caps.name[0..caps.name_len]});
    std.debug.print(&quot;Memory: {} MB\n&quot;, .{caps.total_memory / (1024 * 1024)});
    std.debug.print(&quot;Compute: {}.{}\n&quot;, .{caps.compute_capability[0], caps.compute_capability[1]});

    // 2. Memory operations
    const size: usize = 1024 * @sizeOf(f32);
    const a_ptr = try backend.allocate(size, .{});
    defer backend.free(a_ptr);
    const b_ptr = try backend.allocate(size, .{});
    defer backend.free(b_ptr);
    const c_ptr = try backend.allocate(size, .{});
    defer backend.free(c_ptr);

    // Initialize host data
    var a_host: [1024]f32 = undefined;
    var b_host: [1024]f32 = undefined;
    for (&amp;a_host, &amp;b_host, 0..) |*a, *b, i| {
        a.* = @floatFromInt(i);
        b.* = @floatFromInt(i * 2);
    }

    try backend.copyToDevice(a_ptr, std.mem.sliceAsBytes(&amp;a_host));
    try backend.copyToDevice(b_ptr, std.mem.sliceAsBytes(&amp;b_host));

    // 3. Compile and launch kernel
    const kernel_source =
        \\extern &quot;C&quot; __global__ void vector_add(float* a, float* b, float* c, int n) {
        \\    int i = blockIdx.x * blockDim.x + threadIdx.x;
        \\    if (i &lt; n) c[i] = a[i] + b[i];
        \\}
    ;

    const kernel = backend.compileKernel(allocator, kernel_source, &quot;vector_add&quot;) catch {
        std.debug.print(&quot;Kernel compilation not available (NVRTC missing?)\n&quot;, .{});
        return error.SkipZigTest;
    };
    defer backend.destroyKernel(kernel);

    const config = interface.LaunchConfig{
        .grid_dim = .{ 4, 1, 1 },
        .block_dim = .{ 256, 1, 1 },
        .shared_mem = 0,
        .stream = null,
    };

    const n: i32 = 1024;
    var args: [4]*anyopaque = .{
        @ptrCast(&amp;a_ptr),
        @ptrCast(&amp;b_ptr),
        @ptrCast(&amp;c_ptr),
        @ptrCast(@constCast(&amp;n)),
    };

    try backend.launchKernel(kernel, config, &amp;args);
    try backend.synchronize();

    // 4. Verify results
    var c_host: [1024]f32 = undefined;
    try backend.copyFromDevice(std.mem.sliceAsBytes(&amp;c_host), c_ptr);

    for (c_host, 0..) |val, i| {
        const expected: f32 = @as(f32, @floatFromInt(i)) + @as(f32, @floatFromInt(i * 2));
        try std.testing.expectApproxEqAbs(expected, val, 0.001);
    }

    std.debug.print(&quot;CUDA VTable integration test PASSED\n&quot;, .{});
}
</code></pre>
<p><strong>Step 2: Run integration test</strong></p>
<p>Run: <code>zig test src/compute/gpu/backends/cuda/vtable_test.zig</code>
Expected: PASS (or SkipZigTest on non-CUDA systems)</p>
<p><strong>Step 3: Commit</strong></p>
<pre><code class="language-bash">git add src/compute/gpu/backends/cuda/vtable_test.zig
git commit -m &quot;test(gpu): add CUDA VTable integration tests&quot;
</code></pre>
<hr />
<h2 id="task-10-update-documentation">Task 10: Update Documentation</h2>
<p><strong>Files:</strong>
- Modify: <code>docs/gpu.md</code></p>
<p><strong>Step 1: Add CUDA VTable section</strong></p>
<p>Add to docs/gpu.md:</p>
<pre><code class="language-markdown">## CUDA Backend

The CUDA backend provides full GPU acceleration on NVIDIA hardware.

### Requirements
- NVIDIA GPU (Compute Capability 3.5+)
- CUDA Driver installed
- NVRTC for runtime kernel compilation (optional)

### Usage

```zig
const backend_factory = @import(&quot;abi&quot;).compute.gpu.backend_factory;

// Create CUDA backend
const backend = try backend_factory.createVTableBackend(allocator, .cuda);
defer backend.deinit();

// Query device capabilities
const caps = try backend.getDeviceCaps(0);
std.debug.print(&quot;Device: {s}, Memory: {} GB\n&quot;, .{
    caps.name[0..caps.name_len],
    caps.total_memory / (1024 * 1024 * 1024),
});

// Allocate GPU memory
const ptr = try backend.allocate(size, .{});
defer backend.free(ptr);

// Transfer data
try backend.copyToDevice(ptr, host_data);
// ... execute kernel ...
try backend.copyFromDevice(result, ptr);
</code></pre>
<h3 id="fallback-behavior">Fallback Behavior</h3>
<p>If CUDA is unavailable, the backend factory automatically falls back to the simulated backend for testing/development.</p>
<pre><code>
**Step 2: Commit**

```bash
git add docs/gpu.md
git commit -m &quot;docs(gpu): add CUDA VTable documentation&quot;
</code></pre>
<hr />
<h2 id="summary">Summary</h2>
<table>
<thead>
<tr>
<th>Task</th>
<th>Description</th>
<th>Files</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Create CudaBackend struct</td>
<td>vtable.zig (new)</td>
</tr>
<tr>
<td>2</td>
<td>Device info methods</td>
<td>vtable.zig</td>
</tr>
<tr>
<td>3</td>
<td>Memory operations</td>
<td>vtable.zig</td>
</tr>
<tr>
<td>4</td>
<td>Kernel compilation</td>
<td>vtable.zig</td>
</tr>
<tr>
<td>5</td>
<td>Kernel launch &amp; sync</td>
<td>vtable.zig</td>
</tr>
<tr>
<td>6</td>
<td>VTable wrapper function</td>
<td>vtable.zig</td>
</tr>
<tr>
<td>7</td>
<td>Export from module</td>
<td>mod.zig</td>
</tr>
<tr>
<td>8</td>
<td>Factory integration</td>
<td>backend_factory.zig</td>
</tr>
<tr>
<td>9</td>
<td>Integration tests</td>
<td>vtable_test.zig (new)</td>
</tr>
<tr>
<td>10</td>
<td>Documentation</td>
<td>docs/gpu.md</td>
</tr>
</tbody>
</table>
<p><strong>Total estimated commits:</strong> 10
<strong>New files:</strong> 2
<strong>Modified files:</strong> 3</p>







  
  






                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.sections"], "search": "../../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
    
  </body>
</html>