# CI/local placeholder values for `run_cli_full_matrix.py`.
# Use real credentials only in private environments; these values are non-secret placeholders.
DISCORD_BOT_TOKEN=ci-placeholder-discord-token
ABI_TEST_DISCORD_CHANNEL_ID=ci-placeholder-channel-id
ABI_TEST_DISCORD_WEBHOOK_URL=https://example.invalid/abi/discord/webhook
ABI_TEST_DISCORD_COMMAND_ID=ci-placeholder-command-id

OPENAI_API_KEY=ci-placeholder-openai-key
MISTRAL_API_KEY=ci-placeholder-mistral-key
COHERE_API_KEY=ci-placeholder-cohere-key

OLLAMA_HOST=http://127.0.0.1:11434
ABI_TEST_OLLAMA_MODEL=ci-placeholder-ollama-model

# Absolute path to a local GGUF model for llm/model commands.
ABI_TEST_GGUF_MODEL_PATH=/tmp/abi-cli-full-model.gguf

# Model spec or URL for model/llm download flows.
ABI_TEST_MODEL_SPEC=TheBloke/Llama-2-7B-GGUF:Q4_K_M
