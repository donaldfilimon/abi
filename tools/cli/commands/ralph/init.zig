//! ralph init — Create workspace: ralph.yml, .ralph/, PROMPT.md

const std = @import("std");
const context_mod = @import("../../framework/context.zig");
const utils = @import("../../utils/mod.zig");
const cli_io = utils.io_backend;
const cfg = @import("config.zig");

const TODO_FILE = "tasks/todo.md";
const LESSONS_FILE = "tasks/lessons.md";

const RALPH_YML_TEMPLATE =
    \\# Ralph Orchestrator Configuration
    \\# Generated by: abi ralph init
    \\
    \\cli:
    \\  backend: "{s}"
    \\
    \\llm:
    \\  backend: "{s}"
    \\  fallback: "mlx,ollama,lm_studio,vllm,plugin_http,plugin_native"
    \\  strict_backend: false
    \\  model: "llama3.2"
    \\  plugin: ""
    \\
    \\event_loop:
    \\  prompt_file: "PROMPT.md"
    \\  completion_promise: "LOOP_COMPLETE"
    \\  max_iterations: 5
    \\
    \\execution:
    \\  max_iterations: 5
    \\  max_fix_attempts: 2
    \\  require_clean_tree: true
    \\
    \\gates:
    \\  per_iteration: "zig build verify-all"
    \\
    \\workflow:
    \\  enable_contract: true
    \\  todo_file: "tasks/todo.md"
    \\  lessons_file: "tasks/lessons.md"
    \\  strict_contract: false
    \\
;

const PROMPT_MD_TEMPLATE =
    \\# Ralph Task
    \\
    \\<!-- Replace this with your task description. -->
    \\
    \\## Objective
    \\
    \\Describe the exact outcome Ralph must deliver.
    \\
    \\## Scope
    \\
    \\- In scope:
    \\- Out of scope:
    \\
    \\## Verification Criteria
    \\
    \\- [ ] Gate command(s) and expected result
    \\- [ ] Behavioral checks proving completion
    \\
    \\## Checklist
    \\
    \\- [ ] Plan logged before implementation
    \\- [ ] Changes implemented
    \\- [ ] Verification executed
    \\- [ ] Review captured
    \\
    \\## Review
    \\
    \\- Trigger:
    \\- Impact:
    \\- Plan change:
    \\- Verification change:
    \\
;

const TODO_MD_TEMPLATE =
    \\# Ralph Task Plan
    \\
    \\## Objective
    \\
    \\Describe the exact outcome Ralph must deliver.
    \\
    \\## Scope
    \\
    \\- In scope:
    \\- Out of scope:
    \\
    \\## Verification Criteria
    \\
    \\- [ ] Gate command(s) and expected result
    \\- [ ] Behavioral checks proving completion
    \\
    \\## Checklist
    \\
    \\- [ ] Plan logged before implementation
    \\- [ ] Changes implemented
    \\- [ ] Verification executed
    \\- [ ] Review captured
    \\
    \\## Review
    \\
    \\- Trigger:
    \\- Impact:
    \\- Plan change:
    \\- Verification change:
    \\
;

const LESSONS_MD_TEMPLATE =
    \\# Lessons Learned
    \\
    \\## 1970-01-01 - Initial workspace bootstrap
    \\- Root cause: Initial template entry to satisfy workflow contract checks.
    \\- Prevention rule: Replace this stub with concrete correction patterns after feedback.
    \\
;

pub fn runInit(ctx: *const context_mod.CommandContext, args: []const [:0]const u8) !void {
    const allocator = ctx.allocator;
    var backend: []const u8 = "llama_cpp";
    var force = false;

    var i: usize = 0;
    while (i < args.len) : (i += 1) {
        const arg = std.mem.sliceTo(args[i], 0);
        if (std.mem.eql(u8, arg, "--backend") or std.mem.eql(u8, arg, "-b")) {
            i += 1;
            if (i < args.len) backend = std.mem.sliceTo(args[i], 0);
        } else if (std.mem.eql(u8, arg, "--force") or std.mem.eql(u8, arg, "-f")) {
            force = true;
        } else if (utils.args.matchesAny(arg, &[_][]const u8{ "--help", "-h", "help" })) {
            utils.output.println(
                \\Usage: abi ralph init [options]
                \\
                \\Create a Ralph workspace in the current directory.
                \\
                \\Options:
                \\  -b, --backend <name>  LLM backend (default: llama_cpp)
                \\  -f, --force           Overwrite existing workspace
                \\  -h, --help            Show this help
            , .{});
            return;
        }
    }

    var io_backend = cli_io.initIoBackend(allocator);
    defer io_backend.deinit();
    const io = io_backend.io();

    if (cfg.fileExists(io, cfg.WORKSPACE_DIR ++ "/state.json") and !force) {
        utils.output.printWarning("Workspace already exists (.ralph/). Use --force to reinitialize.", .{});
        return;
    }

    // Create directory tree
    cfg.ensureDir(io, cfg.WORKSPACE_DIR);
    cfg.ensureDir(io, cfg.AGENT_DIR);
    cfg.ensureDir(io, cfg.LOGS_DIR);
    cfg.ensureDir(io, cfg.RUNS_DIR);

    // Write ralph.yml
    const yml = try std.fmt.allocPrint(allocator, RALPH_YML_TEMPLATE, .{ backend, backend });
    defer allocator.free(yml);
    try cfg.writeFile(allocator, io, cfg.CONFIG_FILE, yml);

    // Write PROMPT.md (only if missing or force)
    if (!cfg.fileExists(io, cfg.PROMPT_FILE) or force) {
        try cfg.writeFile(allocator, io, cfg.PROMPT_FILE, PROMPT_MD_TEMPLATE);
    }

    // Write workflow-contract files expected by improve mode.
    cfg.ensureDir(io, "tasks");
    if (!cfg.fileExists(io, TODO_FILE) or force) {
        try cfg.writeFile(allocator, io, TODO_FILE, TODO_MD_TEMPLATE);
    }
    if (!cfg.fileExists(io, LESSONS_FILE) or force) {
        try cfg.writeFile(allocator, io, LESSONS_FILE, LESSONS_MD_TEMPLATE);
    }

    // Write initial state
    cfg.writeState(allocator, io, .{});

    utils.output.printSuccess("Ralph workspace initialized.", .{});
    utils.output.println(
        \\
        \\  ralph.yml   — configuration (backend: {s})
        \\  PROMPT.md   — edit this with your task
        \\  tasks/todo.md      — workflow task plan
        \\  tasks/lessons.md   — workflow correction lessons
        \\  .ralph/     — runtime state directory
        \\
        \\Next steps:
        \\  1. Edit PROMPT.md with your task description
        \\  2. Run: abi ralph run
    , .{backend});
}

test {
    std.testing.refAllDecls(@This());
}
