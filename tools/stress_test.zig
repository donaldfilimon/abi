//! WDBX Stress Testing Tool
//!
//! Validates production database performance under various load conditions:
//! - Concurrent read/write operations
//! - Large-scale vector operations
//! - Memory pressure scenarios
//! - Network saturation testing
//! - Failure recovery validation

const std = @import("std");
const builtin = @import("builtin");

const Config = struct {
    // Connection settings
    host: []const u8 = "localhost",
    port: u16 = 8080,

    // Test parameters
    num_threads: u32 = 32,
    num_vectors: u64 = 1_000_000,
    vector_dimension: u32 = 384,
    duration_seconds: u64 = 300,

    // Operation mix (percentages)
    read_percent: u8 = 70,
    write_percent: u8 = 20,
    delete_percent: u8 = 5,
    search_percent: u8 = 5,

    // Load patterns
    pattern: LoadPattern = .steady,
    burst_size: u32 = 1000,
    burst_interval_ms: u64 = 100,

    const LoadPattern = enum {
        steady,
        burst,
        ramp_up,
        spike,
        random,
    };
};

const Metrics = struct {
    operations: std.atomic.Value(u64),
    successes: std.atomic.Value(u64),
    failures: std.atomic.Value(u64),

    latency_sum: std.atomic.Value(f64),
    latency_count: std.atomic.Value(u64),
    latency_min: std.atomic.Value(u64),
    latency_max: std.atomic.Value(u64),

    throughput: std.atomic.Value(f64),

    start_time: i64,
    end_time: i64,

    fn init() Metrics {
        return .{
            .operations = std.atomic.Value(u64).init(0),
            .successes = std.atomic.Value(u64).init(0),
            .failures = std.atomic.Value(u64).init(0),
            .latency_sum = std.atomic.Value(f64).init(0),
            .latency_count = std.atomic.Value(u64).init(0),
            .latency_min = std.atomic.Value(u64).init(std.math.maxInt(u64)),
            .latency_max = std.atomic.Value(u64).init(0),
            .throughput = std.atomic.Value(f64).init(0),
            .start_time = std.time.milliTimestamp(),
            .end_time = 0,
        };
    }

    fn recordOperation(self: *Metrics, latency_us: u64, success: bool) void {
        _ = self.operations.fetchAdd(1, .monotonic);

        if (success) {
            _ = self.successes.fetchAdd(1, .monotonic);
        } else {
            _ = self.failures.fetchAdd(1, .monotonic);
        }

        _ = self.latency_sum.fetchAdd(@floatFromInt(latency_us), .monotonic);
        _ = self.latency_count.fetchAdd(1, .monotonic);

        // Update min/max
        var current_min = self.latency_min.load(.monotonic);
        while (latency_us < current_min) {
            if (self.latency_min.cmpxchgWeak(current_min, latency_us, .monotonic, .monotonic)) |new_min| {
                current_min = new_min;
            } else {
                break;
            }
        }

        var current_max = self.latency_max.load(.monotonic);
        while (latency_us > current_max) {
            if (self.latency_max.cmpxchgWeak(current_max, latency_us, .monotonic, .monotonic)) |new_max| {
                current_max = new_max;
            } else {
                break;
            }
        }
    }

    fn printSummary(self: *const Metrics) void {
        const total_ops = self.operations.load(.monotonic);
        const success_rate = @as(f64, @floatFromInt(self.successes.load(.monotonic))) /
                           @as(f64, @floatFromInt(total_ops)) * 100.0;

        const avg_latency = self.latency_sum.load(.monotonic) /
                           @as(f64, @floatFromInt(self.latency_count.load(.monotonic)));

        const duration_ms = @as(f64, @floatFromInt(self.end_time - self.start_time));
        const throughput = @as(f64, @floatFromInt(total_ops)) / (duration_ms / 1000.0);

        std.debug.print("\n" ++ "=" ** 60 ++ "\n", .{});
        std.debug.print("üìä **Stress Test Results**\n", .{});
        std.debug.print("=" ** 60 ++ "\n", .{});

        std.debug.print("üìà **Performance Metrics:**\n", .{});
        std.debug.print("  Total Operations:    {}\n", .{total_ops});
        std.debug.print("  Success Rate:        {d:.2}%\n", .{success_rate});
        std.debug.print("  Throughput:          {d:.0} ops/sec\n", .{throughput});

        std.debug.print("\n‚è±Ô∏è  **Latency Statistics:**\n", .{});
        std.debug.print("  Average:             {d:.0} Œºs\n", .{avg_latency});
        std.debug.print("  Minimum:             {} Œºs\n", .{self.latency_min.load(.monotonic)});
        std.debug.print("  Maximum:             {} Œºs\n", .{self.latency_max.load(.monotonic)});

        std.debug.print("\n‚úÖ **Success/Failure Breakdown:**\n", .{});
        std.debug.print("  Successful:          {}\n", .{self.successes.load(.monotonic)});
        std.debug.print("  Failed:              {}\n", .{self.failures.load(.monotonic)});

        std.debug.print("=" ** 60 ++ "\n", .{});
    }
};

const StressTest = struct {
    allocator: std.mem.Allocator,
    config: Config,
    metrics: *Metrics,
    shutdown: std.atomic.Value(bool),
    client: *HttpClient,

    const HttpClient = struct {
        allocator: std.mem.Allocator,
        host: []const u8,
        port: u16,

        fn init(allocator: std.mem.Allocator, host: []const u8, port: u16) !*HttpClient {
            const self = try allocator.create(HttpClient);
            self.* = .{
                .allocator = allocator,
                .host = host,
                .port = port,
            };
            return self;
        }

        fn deinit(self: *HttpClient) void {
            self.allocator.destroy(self);
        }

        fn addVector(self: *HttpClient, vector: []f32) !u64 {
            _ = self;
            _ = vector;
            // Simulate HTTP request
            std.time.sleep(1000 * std.time.ns_per_us);
            return std.crypto.random.int(u64);
        }

        fn searchVector(self: *HttpClient, query: []f32, k: usize) !void {
            _ = self;
            _ = query;
            _ = k;
            // Simulate HTTP request
            std.time.sleep(5000 * std.time.ns_per_us);
        }

        fn getVector(self: *HttpClient, id: u64) !void {
            _ = self;
            _ = id;
            // Simulate HTTP request
            std.time.sleep(500 * std.time.ns_per_us);
        }

        fn deleteVector(self: *HttpClient, id: u64) !void {
            _ = self;
            _ = id;
            // Simulate HTTP request
            std.time.sleep(800 * std.time.ns_per_us);
        }
    };

    fn init(allocator: std.mem.Allocator, config: Config) !*StressTest {
        const self = try allocator.create(StressTest);
        self.* = .{
            .allocator = allocator,
            .config = config,
            .metrics = try allocator.create(Metrics),
            .shutdown = std.atomic.Value(bool).init(false),
            .client = try HttpClient.init(allocator, config.host, config.port),
        };
        self.metrics.* = Metrics.init();
        return self;
    }

    fn deinit(self: *StressTest) void {
        self.client.deinit();
        self.allocator.destroy(self.metrics);
        self.allocator.destroy(self);
    }

    fn run(self: *StressTest) !void {
        std.debug.print("üöÄ Starting stress test...\n", .{});
        std.debug.print("  Threads: {}\n", .{self.config.num_threads});
        std.debug.print("  Vectors: {}\n", .{self.config.num_vectors});
        std.debug.print("  Duration: {} seconds\n", .{self.config.duration_seconds});
        std.debug.print("  Pattern: {s}\n\n", .{@tagName(self.config.pattern)});

        // Create worker threads
        var threads = try self.allocator.alloc(std.Thread, self.config.num_threads);
        defer self.allocator.free(threads);

        // Start workers
        for (threads, 0..) |*thread, i| {
            thread.* = try std.Thread.spawn(.{}, workerThread, .{ self, i });
        }

        // Monitor progress
        var elapsed: u64 = 0;
        while (elapsed < self.config.duration_seconds) {
            std.time.sleep(std.time.ns_per_s);
            elapsed += 1;

            const ops = self.metrics.operations.load(.monotonic);
            const throughput = @as(f64, @floatFromInt(ops)) / @as(f64, @floatFromInt(elapsed));
            self.metrics.throughput.store(throughput, .monotonic);

            if (elapsed % 10 == 0) {
                std.debug.print("‚è±Ô∏è  Progress: {}s / {}s | Throughput: {d:.0} ops/sec\n", .{
                    elapsed,
                    self.config.duration_seconds,
                    throughput,
                });
            }
        }

        // Shutdown
        self.shutdown.store(true, .monotonic);

        // Wait for workers
        for (threads) |thread| {
            thread.join();
        }

        self.metrics.end_time = std.time.milliTimestamp();

        // Print results
        self.metrics.printSummary();
    }

    fn workerThread(self: *StressTest, thread_id: usize) void {
        var prng = std.rand.DefaultPrng.init(@intCast(thread_id));
        const random = prng.random();

        // Pre-generate test vectors
        var test_vector = self.allocator.alloc(f32, self.config.vector_dimension) catch return;
        defer self.allocator.free(test_vector);

        for (test_vector) |*v| {
            v.* = random.float(f32);
        }

        var vector_ids = std.ArrayList(u64).init(self.allocator);
        defer vector_ids.deinit();

        while (!self.shutdown.load(.monotonic)) {
            // Determine operation based on configured mix
            const op_type = random.intRangeAtMost(u8, 0, 99);

            const start = std.time.microTimestamp();
            var success = true;

            if (op_type < self.config.write_percent) {
                // Write operation
                const id = self.client.addVector(test_vector) catch {
                    success = false;
                    continue;
                };
                vector_ids.append(id) catch {};

            } else if (op_type < self.config.write_percent + self.config.read_percent) {
                // Read operation
                if (vector_ids.items.len > 0) {
                    const idx = random.intRangeLessThan(usize, 0, vector_ids.items.len);
                    self.client.getVector(vector_ids.items[idx]) catch {
                        success = false;
                    };
                }

            } else if (op_type < self.config.write_percent + self.config.read_percent + self.config.search_percent) {
                // Search operation
                self.client.searchVector(test_vector, 10) catch {
                    success = false;
                };

            } else {
                // Delete operation
                if (vector_ids.items.len > 0) {
                    const idx = random.intRangeLessThan(usize, 0, vector_ids.items.len);
                    const id = vector_ids.items[idx];
                    self.client.deleteVector(id) catch {
                        success = false;
                    };
                    _ = vector_ids.swapRemove(idx);
                }
            }

            const latency = @as(u64, @intCast(std.time.microTimestamp() - start));
            self.metrics.recordOperation(latency, success);

            // Apply load pattern
            self.applyLoadPattern(thread_id);
        }
    }

    fn applyLoadPattern(self: *StressTest, thread_id: usize) void {
        switch (self.config.pattern) {
            .steady => {
                // Constant rate
                std.time.sleep(10 * std.time.ns_per_ms);
            },
            .burst => {
                // Burst pattern
                if (thread_id % 4 == 0) {
                    std.time.sleep(self.config.burst_interval_ms * std.time.ns_per_ms);
                }
            },
            .ramp_up => {
                // Gradually increase load
                const elapsed = std.time.milliTimestamp() - self.metrics.start_time;
                const delay = @max(1, 100 - @divTrunc(elapsed, 1000));
                std.time.sleep(@intCast(delay * std.time.ns_per_ms));
            },
            .spike => {
                // Occasional spikes
                if (std.crypto.random.int(u32) % 100 < 5) {
                    // 5% chance of no delay (spike)
                } else {
                    std.time.sleep(50 * std.time.ns_per_ms);
                }
            },
            .random => {
                // Random delays
                const delay = std.crypto.random.intRangeAtMost(u64, 1, 100);
                std.time.sleep(delay * std.time.ns_per_ms);
            },
        }
    }
};

pub fn main() !void {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer _ = gpa.deinit();
    const allocator = gpa.allocator();

    // Parse command-line arguments
    const args = try std.process.argsAlloc(allocator);
    defer std.process.argsFree(allocator, args);

    var config = Config{};

    var i: usize = 1;
    while (i < args.len) : (i += 1) {
        if (std.mem.eql(u8, args[i], "--host") and i + 1 < args.len) {
            i += 1;
            config.host = args[i];
        } else if (std.mem.eql(u8, args[i], "--port") and i + 1 < args.len) {
            i += 1;
            config.port = try std.fmt.parseInt(u16, args[i], 10);
        } else if (std.mem.eql(u8, args[i], "--threads") and i + 1 < args.len) {
            i += 1;
            config.num_threads = try std.fmt.parseInt(u32, args[i], 10);
        } else if (std.mem.eql(u8, args[i], "--vectors") and i + 1 < args.len) {
            i += 1;
            config.num_vectors = try std.fmt.parseInt(u64, args[i], 10);
        } else if (std.mem.eql(u8, args[i], "--duration") and i + 1 < args.len) {
            i += 1;
            config.duration_seconds = try std.fmt.parseInt(u64, args[i], 10);
        } else if (std.mem.eql(u8, args[i], "--pattern") and i + 1 < args.len) {
            i += 1;
            config.pattern = std.meta.stringToEnum(Config.LoadPattern, args[i]) orelse .steady;
        } else if (std.mem.eql(u8, args[i], "--help")) {
            printHelp();
            return;
        }
    }

    // Run stress test
    const test = try StressTest.init(allocator, config);
    defer test.deinit();

    try test.run();
}

fn printHelp() void {
    std.debug.print(
        \\WDBX Stress Testing Tool
        \\
        \\Usage: wdbx_stress_test [options]
        \\
        \\Options:
        \\  --host <host>       Target host (default: localhost)
        \\  --port <port>       Target port (default: 8080)
        \\  --threads <n>       Number of worker threads (default: 32)
        \\  --vectors <n>       Number of vectors to test (default: 1000000)
        \\  --duration <s>      Test duration in seconds (default: 300)
        \\  --pattern <type>    Load pattern: steady|burst|ramp_up|spike|random
        \\  --help              Show this help message
        \\
        \\Examples:
        \\  # Basic stress test
        \\  wdbx_stress_test --threads 64 --duration 600
        \\
        \\  # Burst pattern test
        \\  wdbx_stress_test --pattern burst --vectors 10000000
        \\
        \\  # Production validation
        \\  wdbx_stress_test --host prod.example.com --threads 128 --duration 3600
        \\
    , .{});
}
